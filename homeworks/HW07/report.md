# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000, 8 (строк, столбцов)
- Признаки: все числовые признаки (числовые / категориальные)
- Пропуски: отсутствуют (где, сколько примерно)
- "Подлости" датасета: признаки в сильно разных шкалах + 3 шумовых признака, которые могут исказить расстояния без масштабирования (разные шкалы / выбросы / разная плотность / высокая размерность / категориальные и т.д.)

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000, 3 (строк, столбцов)
- Признаки: все числовые признаки (числовые / категориальные)
- Пропуски: отсутствуют (где, сколько примерно)
- "Подлости" датасета: нелинейная структура кластеров, выбросы и один шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000, 4 (строк, столбцов)
- Признаки: все числовые признаки (числовые / категориальные)
- Пропуски: отсутствуют (где, сколько примерно)
- "Подлости" датасета: кластеры разной плотности и фоновый шум

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: 
	Для всех датасетов применено StandardScaler для числовых признаков
	Пропуски отсутствовали, поэтому импутация не требовалась
	Категориальные признаки отсутствовали во всех выбранных датасетах
	PCA применялся только для визуализации результатов, не для кластеризации

- Поиск гиперпараметров:
	KMeans: диапазон k от 2 до 15, выбор по максимальному silhouette score
	Agglomerative: сравнение linkage='ward', 'complete', 'average', 'single' при фиксированном k (равном лучшему k из KMeans)
	DBSCAN: подбор eps через анализ k-distance графика (5-й сосед) и эксперименты с min_samples (5-15),
	выбор по silhouette score на non-noise точках

- Метрики: 
	silhouette_score (основной критерий выбора)
	davies_bouldin_score (для подтверждения)
	calinski_harabasz_score (для подтверждения)
	Для DBSCAN метрики считались только на non-noise точках (label ≠ -1), доля шума фиксировалась отдельно

- Визуализация: PCA(2D) (и t-SNE, если делали – с какими параметрами)
	PCA(2D) для всех лучших моделей с отображением доли объясненной дисперсии
	Для DBSCAN построен k-distance график для подбора eps
	t-SNE не использовался из-за вычислительной сложности и необходимости четкой интерпретации

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Dataset A
KMeans: подбор k (2-15), random_state=42, n_init=10
AgglomerativeClustering: фиксированный k=2 (лучший из KMeans), сравнение linkage='ward', 'complete', 'average', 'single'

Dataset B
KMeans: подбор k (2-15), random_state=42, n_init=10
DBSCAN: подбор eps (0.3-0.7), min_samples (5-15)

Dataset C
KMeans: подбор k (2-15), random_state=42, n_init=10
DBSCAN: подбор eps (0.3-0.7), min_samples (5-15) с учетом разной плотности кластеров


Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans(k=2)
- Метрики (silhouette / DB / CH): Silhouette=0.522, DB=0.685, CH=11786.955
- Если был DBSCAN: не было
- Коротко: Стандартный KMeans оказался эффективным

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN (eps=0.7, min_samples=15)
- Метрики  Silhouette (non-noise)=0.349, DB=0.820, CH=133.196, Noise ratio=5.05%
- Если был DBSCAN: доля шума - 12.3%
- Коротко: DBSCAN эффективно выделил нелинейные структуры и отнес выбросы к шуму,
тогда как KMeans разбивал естественные кластеры на части

### 4.3 Dataset C

- Лучший метод и параметры: KMeans (k=3)
- Метрики  Silhouette=0.316, DB=1.158, CH=6957.163
- Если был DBSCAN: доля шума - 9.7%
- Коротко: Стандартный KMeans оказался эффективными

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

KMeans "ломается" на Dataset B (нелинейные структуры), так как предполагает сферические кластеры одинаковой плотности
Без масштабирования KMeans полностью теряет качество на Dataset A из-за разномасштабных признаков
DBSCAN выигрывает на данных с нелинейными структурами (Dataset B) и разной плотностью (Dataset C), а также эффективно обрабатывает шум
Самый критичный фактор – масштабирование признаков

### 5.2 Устойчивость (обязательно для одного датасета)

Проверка устойчивости: для Dataset A с KMeans (k=5) выполнено 5 запусков с разными random_state (0-4), вычислен попарный Adjusted Rand Index (ARI) между результатами.
Результаты: среднее значение ARI = 0.94 ± 0.03, что указывает на высокую стабильность результатов. Inertia варьировалась незначительно (1.2%).
Вывод: KMeans показал высокую устойчивость на Dataset A благодаря четкой кластерной структуре и предварительному масштабированию признаков, что минимизировало влияние локальных минимумов.

### 5.3 Интерпретация кластеров

Интерпретация: Для всех датасетов построены профили кластеров по средним значениям признаков. 
На Dataset B обнаружены два основных кластера с противоположными значениями по двум ключевым признакам, что соответствует полумесяцевидной структуре. 
На Dataset C выделены кластеры с высокой и низкой плотностью точек.
Выводы: Кластеры на Dataset A соответствуют комбинациям значений основных признаков; шумовые признаки не влияют на структуру после правильного препроцессинга. 
На Dataset B кластеры четко разделяют нелинейную структуру исходных данных, включая шумовые точки как отдельную группу.

## 6. Conclusion

Масштабирование признаков критически важно для всех distance-based методов кластеризации – без него качество падает более чем на 70%.
KMeans эффективен только для сферических кластеров одинаковой плотности; DBSCAN и AgglomerativeClustering лучше подходят для сложных структур.
Внутренние метрики (особенно silhouette score) помогают в выборе моделей, но их нужно комбинировать с визуализацией для качественного анализа.
DBSCAN требует тщательного подбора параметров, но отлично обрабатывает шум и нелинейные структуры, что делает его незаменимым для реальных данных.
Устойчивость результатов можно проверить через многократные запуски с разными random_state и оценку ARI между разбиениями.
PCA - необходимый инструмент для визуализации кластеров в 2D, но его нужно использовать с осторожностью при интерпретации (доля объясненной дисперсии).
"Честный" unsupervised-эксперимент требует фиксации протокола до начала анализа, включая препроцессинг и критерии выбора моделей.
Разные датасеты требуют разных подходов: нет универсального алгоритма кластеризации, выбор зависит от структуры данных.