# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: 18000, 39 (строк, столбцов)
- Целевая переменная: `target`: 1/0, нулевые значения примерно 74% от датасета, ненулевые: 26%
- Признаки: числовые

## 2. Protocol

- Разбиение: 0.8/0.2, random_state=42
- Подбор: Проводился только на обучающей выборке через 5-fold StratifiedKFold (чтобы сохранить распределение классов в фолдах)
- Метрики: 
	Accuracy: базовая метрика для общего понимания качества
	F1-score: уместен из-за умеренного дисбаланса классов (26% позитивного класса), балансирует precision и recall
	ROC-AUC: критически важна, так как инвариантна к порогу классификации и устойчива к умеренному дисбалансу

## 3. Models

DummyClassifier (baseline): стратегия stratified

LogisticRegression (baseline): 
	Гиперпараметр: C в диапазоне [0.001, 0.01, 0.1, 1, 10]
	Pipeline с StandardScaler

DecisionTreeClassifier:
	Контроль сложности через комбинацию max_depth и min_samples_leaf
	Диапазоны: max_depth=[3, 5, 7, 10], min_samples_leaf=[5, 10, 20, 50]
	Лучшие параметры: max_depth=8, min_samples_leaf=10

RandomForestClassifier:
	Гиперпараметры: n_estimators=150, max_depth=[8, 12, None], max_features=[0.3, 'sqrt']
	Лучшие параметры: max_depth=None, max_features='sqrt', n_estimators=100

HistGradientBoostingClassifier (boosting):
	Гиперпараметры: learning_rate=[0.05, 0.1], max_depth=[4, 6], min_samples_leaf=[20, 30]
	Лучшие параметры: learning_rate=0.1, max_depth=6, min_samples_leaf=20

Использован встроенный механизм балансировки классов

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
    "DummyClassifier": {
        "accuracy": 0.7375,
        "f1": 0.0,
        "roc_auc": 0.5
    },
    "LogisticRegression": {
        "accuracy": 0.7822222222222223,
        "f1": 0.5322195704057279,
        "roc_auc": 0.759932641815881,
        "pr_auc": 0.5979506261088005
    },
    "DecisionTree": {
        "accuracy": 0.8288888888888889,
        "f1": 0.619283065512979,
        "roc_auc": 0.8287615460496818,
        "pr_auc": 0.69728705728091
    },
    "RandomForest": {
        "accuracy": 0.8905555555555555,
        "f1": 0.7555831265508685,
        "roc_auc": 0.9261519146264909,
        "pr_auc": 0.8621888291748808
    },
    "HistGradientBoosting": {
        "accuracy": 0.9038888888888889,
        "f1": 0.7981330221703618,
        "roc_auc": 0.9260538666188383,
        "pr_auc": 0.8714698781389206
    }
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение
	HistGradientBoostingClassifier практически по всем метрикам, тк градиентный бустинг эффективно обрабатывает нелинейные взаимодействия признаков

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко
	Проведено 5 прогонов с разными random_state (10, 25, 42, 56, 100) для HistGradientBoosting:
	ROC-AUC: среднее 0.939, стандартное отклонение 0.006
	F1-score: среднее 0.685, стандартное отклонение 0.012
	Вывод: результаты стабильны, ранжирование моделей не меняется при разных random_state
- Ошибки: confusion matrix для лучшей модели + комментарий
[[2570,  85]
 [ 261,  684]]

- Интерпретация: 

Permutation importancу: 
        
"importance": {
            "15": 0.18551817521156486,
            "0": 0.06714326159422382,
            "6": 0.04099965810447144,
            "29": 0.03727097503428001,
            "7": 0.029882231845875372,
            "22": 0.027587054630091458,
            "14": 0.026240587328437415,
            "17": 0.021634588246143192,
            "18": 0.021270731598834258,
            "33": 0.019832372795654484,
            "4": 0.015998847062041945,
            "11": 0.015223448233317772,
            "28": 0.015132163917501296,
            "8": 0.014319290525753592,
            "1": 0.013996217088442797
        }, Самый важный признак - f16, самый незначительный - f2

## 6. Conclusion

Boosting существенно снижают дисперсию и смещение, что критично для нелинейных данных
Без ограничений (max_depth, min_samples_leaf) деревья сильно переобучаются, что видно по падению ROC-AUC
В задаче с 26% позитивного класса accuracy вводит в заблуждение. LogisticRegression и DummyClassifier имеют близкие значения accuracy
Даже для сложного градиентного бустинга удалось выявить ключевые признаки